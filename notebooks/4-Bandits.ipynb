{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erichsdb/Deep-Reinforcement-Learning/blob/main/notebooks/4-Bandits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj-rXPzpaT8Y"
      },
      "source": [
        "# Bandits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjTgnfoaT8c"
      },
      "source": [
        "In this part, we will investigate the properties of the action selection schemes seen in the lecture and compare their properties:\n",
        "\n",
        "1. greedy action selection\n",
        "2. $\\epsilon$-greedy action selection\n",
        "3. softmax action selection\n",
        "\n",
        "Let's re-use the definitions of the last exercise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zi22kvlfaT8e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AYJSXidZaT8f"
      },
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    \"\"\"\n",
        "    n-armed bandit.\n",
        "    \"\"\"\n",
        "    def __init__(self, nb_actions, mean=0.0, std_Q=1.0, std_r=1.0):\n",
        "        \"\"\"\n",
        "        :param nb_actions: number of arms.\n",
        "        :param mean: mean of the normal distribution for $Q^*$.\n",
        "        :param std_Q: standard deviation of the normal distribution for $Q^*$.\n",
        "        :param std_r: standard deviation of the normal distribution for the sampled rewards.\n",
        "        \"\"\"\n",
        "        # Store parameters\n",
        "        self.nb_actions = nb_actions\n",
        "        self.mean = mean\n",
        "        self.std_Q = std_Q\n",
        "        self.std_r = std_r\n",
        "\n",
        "        # Initialize the true Q-values\n",
        "        self.Q_star = rng.normal(self.mean, self.std_Q, self.nb_actions)\n",
        "\n",
        "        # Optimal action\n",
        "        self.a_star = self.Q_star.argmax()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Sampled a single reward from the bandit.\n",
        "\n",
        "        :param action: the selected action.\n",
        "        :return: a reward.\n",
        "        \"\"\"\n",
        "        return float(rng.normal(self.Q_star[action], self.std_r, 1)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N4KoNm8ZaT8h",
        "outputId": "b5c7dcbf-6834-475d-86fe-48cb3bcdea05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.28897433 -1.53735753  0.79026952  0.43303769 -1.64464805]\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "nb_actions = 5\n",
        "bandit = Bandit(nb_actions)\n",
        "\n",
        "print(bandit.Q_star)\n",
        "print(bandit.a_star)\n",
        "\n",
        "all_rewards = []\n",
        "for t in range(1000):\n",
        "    rewards = []\n",
        "    for a in range(nb_actions):\n",
        "        rewards.append(bandit.step(a))\n",
        "    all_rewards.append(rewards)\n",
        "\n",
        "mean_reward = np.mean(all_rewards, axis=0)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.bar(range(nb_actions), bandit.Q_star)\n",
        "plt.xlabel(\"Actions\")\n",
        "plt.ylabel(\"$Q^*(a)$\")\n",
        "plt.subplot(132)\n",
        "plt.bar(range(nb_actions), mean_reward)\n",
        "plt.xlabel(\"Actions\")\n",
        "plt.ylabel(\"$Q_t(a)$\")\n",
        "plt.subplot(133)\n",
        "plt.bar(range(nb_actions), np.abs(bandit.Q_star - mean_reward))\n",
        "plt.xlabel(\"Actions\")\n",
        "plt.ylabel(\"Absolute error\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yNrKI_faT8j"
      },
      "source": [
        "## Greedy action selection\n",
        "\n",
        "In **greedy action selection**, we systematically chose the action with the highest estimated Q-value at each play (or randomly when there are ties):\n",
        "\n",
        "$$a_t = \\text{argmax}_a Q_t(a)$$\n",
        "\n",
        "We maintain estimates $Q_t$ of the action values (initialized to 0) using the online formula:\n",
        "\n",
        "$$Q_{t+1}(a_t) = Q_t(a_t) + \\alpha \\, (r_{t} - Q_t(a_t))$$\n",
        "\n",
        "when receiving the sampled reward $r_t$ after taking the action $a_t$. The learning rate $\\alpha$ can be set to 0.1 at first.\n",
        "\n",
        "The algorithm simply alternates between these two steps for 1000 plays (or steps): take an action, update its Q-value.\n",
        "\n",
        "**Q:** Implement the greedy algorithm on the 5-armed bandit.\n",
        "\n",
        "Your algorithm will look like this:\n",
        "\n",
        "* Create a 5-armed bandit (mean of zero, variance of 1).\n",
        "* Initialize the estimated Q-values to 0 with an array of the same size as the bandit.\n",
        "* **for** 1000 plays:\n",
        "    * Select the greedy action $a_t^*$ using the current estimates.\n",
        "    * Sample a reward from $\\mathcal{N}(Q^*(a_t^*), 1)$.\n",
        "    * Update the estimated Q-value of the action taken.\n",
        "    \n",
        "Additionally, you will store the received rewards at each step in an initially empty list or a numpy array of the correct size and plot it in the end. You will also plot the true Q-values and the estimated Q-values at the end of the 1000 plays.\n",
        "\n",
        "*Tip:* to implement the argmax, do not rely on `np.argmax()`. If there are ties in the array, for example at the beginning:\n",
        "\n",
        "```python\n",
        "x = np.array([0, 0, 0, 0, 0])\n",
        "```\n",
        "\n",
        "`x.argmax()` will return you the **first occurrence** of the maximum 0.0 of the array. In this case it will be the index 0, so you will always select the action 0 first.\n",
        "\n",
        "It is much more efficient to retrieve the indices of **all** maxima and randomly select one of them:\n",
        "\n",
        "```python\n",
        "a = rng.choice(np.where(x == x.max())[0])\n",
        "```\n",
        "\n",
        "`np.where(x == x.max())` returns a list of indices where `x` is maximum. `rng.choice()` randomly selects one of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pCafugQ9aT8k",
        "outputId": "e24d1943-d763-480a-9ebe-31d6a68e7648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bandit reward: [ 0.70754233  0.32102694  1.03745535 -1.44912731  0.04972952]\n",
            "Estimated reward: [ 0.          0.          0.90558552 -0.27868164  0.        ]\n",
            "Best bandit action is 2, best estimated action is 2\n"
          ]
        }
      ],
      "source": [
        "nb_actions = 5\n",
        "bandit = Bandit(nb_actions)\n",
        "\n",
        "alpha = 0.1\n",
        "\n",
        "print(f\"Bandit reward: {bandit.Q_star}\")\n",
        "\n",
        "reward_estimate = np.zeros(nb_actions)\n",
        "\n",
        "for t in range(1000):\n",
        "    a = rng.choice(np.where(reward_estimate == reward_estimate.max())[0])\n",
        "\n",
        "    reward_estimate[a] = reward_estimate[a] + alpha * (bandit.step(a) - reward_estimate[a])\n",
        "\n",
        "print(f\"Estimated reward: {reward_estimate}\")\n",
        "print(f\"Best bandit action is {bandit.a_star}, best estimated action is {reward_estimate.argmax()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDzKXgkkaT8k"
      },
      "source": [
        "**Q:** Re-run your algorithm multiple times with different values of $Q^*$ (simply recreate the `Bandit`) and observe:\n",
        "\n",
        "1. How much reward you get.\n",
        "2. How your estimated Q-values in the end differ from the true Q-values.\n",
        "3. Whether greedy action action selection finds the optimal action or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIE7_gMjaT8l"
      },
      "source": [
        "Before going further, let's turn the agent into a class for better reusability.\n",
        "\n",
        "**Q:** Create a `GreedyAgent` class taking the bandit as an argument as well as the learning rate `alpha=0.1`:\n",
        "\n",
        "```python\n",
        "bandit = Bandit(nb_actions)\n",
        "\n",
        "agent = GreedyAgent(bandit, alpha=0.1)\n",
        "```\n",
        "\n",
        "The constructor should initialize the array of estimated Q-values `Q_t` and store it as an attribute.\n",
        "\n",
        "Define a method `act(self)` that returns the index of the greedy action based on the current estimates, as well as a method `update(self, action, reward)` that allows to update the estimated Q-value of the action given the obtained reward. Define also a `train(self, nb_steps)` method that implements the complete training process for `nb_steps=1000` plays and returns the list of obtained rewards.\n",
        "\n",
        "```python\n",
        "class GreedyAgent:\n",
        "    def __init__(self, bandit, alpha):\n",
        "        # TODO\n",
        "        \n",
        "    def act(self):      \n",
        "        action = # TODO\n",
        "        return action\n",
        "        \n",
        "    def update(self, action, reward):\n",
        "        # TODO\n",
        "        \n",
        "    def train(self, nb_steps):\n",
        "        # TODO\n",
        "```\n",
        "\n",
        "Re-run the experiment using this Greedy agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_jJjg3eSaT8q"
      },
      "outputs": [],
      "source": [
        "class GreedyAgent:\n",
        "    def __init__(self, bandit, alpha):\n",
        "        self.bandit = bandit\n",
        "        self.alpha = alpha\n",
        "        self.Q_t = np.zeros(bandit.nb_actions)\n",
        "\n",
        "    def act(self):\n",
        "        action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "        return action\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        self.Q_t[action] = self.Q_t[action] + self.alpha * (reward - self.Q_t[action])\n",
        "\n",
        "    def train(self, nb_steps):\n",
        "        for t in range(nb_steps):\n",
        "          action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "          reward = self.bandit.step(action)\n",
        "          self.update(action, reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7vcaRgI9aT8r",
        "outputId": "d49af944-2774-44c6-be40-8d4a13f1edfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bandit reward: [ 0.96515458  2.04556643 -0.55963638  1.19048819  1.18252583]\n",
            "Estimated reward: [0.        0.        0.        1.5793972 0.       ]\n",
            "Best bandit action is 1, best estimated action is 3\n"
          ]
        }
      ],
      "source": [
        "bandit = Bandit(nb_actions)\n",
        "\n",
        "agent = GreedyAgent(bandit, alpha=0.1)\n",
        "agent.train(1000)\n",
        "\n",
        "print(f\"Bandit reward: {bandit.Q_star}\")\n",
        "print(f\"Estimated reward: {agent.Q_t}\")\n",
        "print(f\"Best bandit action is {bandit.a_star}, best estimated action is {agent.act()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w20z8JwFaT8r"
      },
      "source": [
        "**Q:** Modify the `train()` method so that it also returns a list of binary values (0 and 1) indicating for each play whether the agent chose the optimal action. Plot this list and observe the lack of exploration.\n",
        "\n",
        "*Hint:* the index of the optimal action is already stored in the bandit: `bandit.a_star`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p3IgDNuZaT8s"
      },
      "outputs": [],
      "source": [
        "class GreedyAgent:\n",
        "    def __init__(self, bandit, alpha):\n",
        "        self.bandit = bandit\n",
        "        self.alpha = alpha\n",
        "        self.Q_t = np.zeros(bandit.nb_actions)\n",
        "\n",
        "        self.optimal_action = []\n",
        "\n",
        "    def act(self):\n",
        "        action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "        return action\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        self.Q_t[action] = self.Q_t[action] + self.alpha * (reward - self.Q_t[action])\n",
        "\n",
        "    def train(self, nb_steps):\n",
        "        for t in range(nb_steps):\n",
        "          action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "          reward = self.bandit.step(action)\n",
        "          self.update(action, reward)\n",
        "\n",
        "\n",
        "          if a == bandit.a_star:\n",
        "            self.optimal_action.append(1)\n",
        "          else:\n",
        "            self.optimal_action.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r_vzEjvUaT8s",
        "outputId": "a320c961-b020-48fd-e731-bed0d94d055e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bandit reward: [ 1.40179071  1.87511446 -0.37108098 -0.79749061 -1.3248293 ]\n",
            "Estimated reward: [ 0.          1.49194685 -0.04078468 -0.13533896 -0.18288333]\n",
            "Best bandit action is 1, best estimated action is 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bandit = Bandit(nb_actions)\n",
        "\n",
        "agent = GreedyAgent(bandit, alpha=0.1)\n",
        "agent.train(200)\n",
        "\n",
        "print(f\"Bandit reward: {bandit.Q_star}\")\n",
        "print(f\"Estimated reward: {agent.Q_t}\")\n",
        "print(f\"Best bandit action is {bandit.a_star}, best estimated action is {agent.act()}\")\n",
        "\n",
        "plt.plot(agent.optimal_action)\n",
        "plt.xlabel(\"Plays\")\n",
        "plt.ylabel(\"Optimal action\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfztv3uwaT8t"
      },
      "source": [
        "\n",
        "\n",
        "The evolution of the received rewards and optimal actions does not give a clear indication of the successful learning, as it is strongly dependent on the true Q-values. To truly estimate the performance of the algorithm, we have to average these results over many runs, e.g. 200.\n",
        "\n",
        "**Q:** Run the learning procedure 200 times (new bandit and agent every time) and average the results. Give a unique name to these arrays (e.g. `rewards_greedy` and `optimal_greedy`) as we will do comparisons later. Compare the results with the lecture, where a 10-armed bandit was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6COwxALaT8t"
      },
      "outputs": [],
      "source": [
        "nb_actions = 5\n",
        "\n",
        "rewards_greedy = []\n",
        "optimal_greedy = []\n",
        "\n",
        "for i in range(200):\n",
        "  bandit = Bandit(nb_actions)\n",
        "  agent = GreedyAgent(bandit, alpha=0.1)\n",
        "  agent.train(200)\n",
        "\n",
        "  rewards_greedy.append(agent.Q_t)\n",
        "  optimal_greedy.append(1) if agent.act() == bandit.a_star else optimal_greedy.append(0)\n",
        "\n",
        "rewards_greedy = np.mean(rewards_greedy, axis=0)\n",
        "optimal_greedy = np.mean(optimal_greedy, axis=0)\n",
        "\n",
        "print(optimal_greedy)\n",
        "print(rewards_greedy)\n",
        "# höher als mit 10, etwa 75-80% das richtige Ergebnis. Bei 10 sind es etwa 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5FgJDOaT8t"
      },
      "source": [
        "## $\\epsilon$-greedy action selection\n",
        "\n",
        "The main drawback of greedy action selection is that it does not explore: as soon as it finds an action better than the others (with a sufficiently positive true Q-value, i.e. where the sampled rewards are mostly positive), it will keep selecting that action and avoid exploring the other options.\n",
        "\n",
        "The estimated Q-value of the selected action will end up being quite correct, but those of the other actions will stay at 0.\n",
        "\n",
        "In $\\epsilon$-greedy action selection, the greedy action $a_t^*$ (with the highest estimated Q-value) will be selected with a probability $1-\\epsilon$, the others with a probability of $\\epsilon$ altogether.\n",
        "\n",
        "$$\n",
        "    \\pi(a) = \\begin{cases} 1 - \\epsilon \\; \\text{if} \\; a = a_t^* \\\\ \\frac{\\epsilon}{|\\mathcal{A}| - 1} \\; \\text{otherwise.} \\end{cases}\n",
        "$$\n",
        "\n",
        "If you have $|\\mathcal{A}| = 5$ actions, the four non-greedy actions will be selected with a probability of $\\frac{\\epsilon}{4}$.\n",
        "\n",
        "**Q:** Create a `EpsilonGreedyAgent` (possibly inheriting from `GreedyAgent` to reuse code) to implement $\\epsilon$-greedy action selection (with $\\epsilon=0.1$ at first). Do not overwrite the arrays previously calculated (mean reward and optimal actions), as you will want to compare the two methods in a single plot.\n",
        "\n",
        "To implement $\\epsilon-$greedy, you need to:\n",
        "\n",
        "1. Select the greedy action $a = a^*_t$.\n",
        "2. Draw a random number between 0 and 1 (`rng.random()`).\n",
        "3. If this number is smaller than $\\epsilon$, you need to select another action randomly in the remaining ones (`rng.choice()`).\n",
        "4. Otherwise, keep the greedy action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "v6fqytXBaT8u"
      },
      "outputs": [],
      "source": [
        "class EpsilonGreedyAgent:\n",
        "    def __init__(self, bandit, alpha, epsilon):\n",
        "        self.bandit = bandit\n",
        "        self.alpha = alpha\n",
        "        self.Q_t = np.zeros(bandit.nb_actions)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.optimal_action = []\n",
        "\n",
        "    def act(self):\n",
        "        action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "        return action\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        self.Q_t[action] = self.Q_t[action] + self.alpha * (reward - self.Q_t[action])\n",
        "\n",
        "    def train(self, nb_steps):\n",
        "        for t in range(nb_steps):\n",
        "          action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "\n",
        "          # eta selection\n",
        "          if rng.random() < self.epsilon:\n",
        "            action = rng.choice([i for i in range(self.bandit.nb_actions) if i != action])\n",
        "\n",
        "          reward = self.bandit.step(action)\n",
        "          self.update(action, reward)\n",
        "\n",
        "\n",
        "          if a == bandit.a_star:\n",
        "            self.optimal_action.append(1)\n",
        "          else:\n",
        "            self.optimal_action.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "haiKx5yoaT8u",
        "outputId": "f4471c3f-337b-4a84-cc57-300039deab06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n",
            "[ 0.20902354  0.08824536 -0.02611634  0.15075475  0.11811584]\n"
          ]
        }
      ],
      "source": [
        "nb_actions = 5\n",
        "\n",
        "rewards_epsilon_greedy = []\n",
        "optimal_epsilon_greedy = []\n",
        "\n",
        "for i in range(200):\n",
        "  bandit = Bandit(nb_actions)\n",
        "  agent = EpsilonGreedyAgent(bandit, alpha=0.1, epsilon=0.1)\n",
        "  agent.train(200)\n",
        "\n",
        "  rewards_epsilon_greedy.append(agent.Q_t)\n",
        "  optimal_epsilon_greedy.append(1) if agent.act() == bandit.a_star else optimal_epsilon_greedy.append(0)\n",
        "\n",
        "optimal_epsilon_greedy = np.mean(optimal_epsilon_greedy, axis=0)\n",
        "rewards_epsilon_greedy = np.mean(rewards_epsilon_greedy, axis=0)\n",
        "\n",
        "print(optimal_epsilon_greedy)\n",
        "print(rewards_epsilon_greedy)\n",
        "# besser als Greedy (5-10% bei eps=0.1, sonst schlechter (ähnlich))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2rJVbfaT8u"
      },
      "source": [
        "**Q:** Compare the properties of greedy and $\\epsilon$-greedy (speed, optimality, etc). Vary the value of the parameter $\\epsilon$ (0.0001 until 0.5) and conclude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUaetJOSaT8v"
      },
      "source": [
        "\n",
        "## Softmax action selection\n",
        "\n",
        "To avoid exploring actions which are clearly not optimal, another useful algorithm is **softmax action selection**. In this scheme, the estimated Q-values are ransformed into a probability distribution using the softmax opertion:\n",
        "\n",
        "$$\n",
        "    \\pi(a) = \\frac{\\exp \\frac{Q_t(a)}{\\tau}}{ \\sum_b \\exp \\frac{Q_t(b)}{\\tau}}\n",
        "$$\n",
        "\n",
        "For each action, the term $\\exp \\frac{Q_t(a)}{\\tau}$ is proportional to $Q_t(a)$ but made positive. These terms are then normalized by the denominator in order to obtain a sum of 1, i.e. they are the parameters of a discrete probability distribution. The temperature $\\tau$ controls the level of exploration just as $\\epsilon$ for $\\epsilon$-greedy.\n",
        "\n",
        "In practice, $\\exp \\frac{Q_t(a)}{\\tau}$ can be very huge if the Q-values are high or the temperature is small, creating numerical instability (NaN). It is much more stable to substract the maximal Q-value from all Q-values before applying the softmax:\n",
        "\n",
        "$$\n",
        "    \\pi(a) = \\frac{\\exp \\displaystyle\\frac{Q_t(a) - \\max_a Q_t(a)}{\\tau}}{ \\sum_b \\exp \\displaystyle\\frac{Q_t(b) - \\max_b Q_t(b)}{\\tau}}\n",
        "$$\n",
        "\n",
        "This way, $Q_t(a) - \\max_a Q_t(a)$ is always negative, so its exponential is between 0 and 1.\n",
        "\n",
        "**Q:** Implement the softmax action selection (with $\\tau=0.5$ at first) and compare its performance to greedy and $\\epsilon$-greedy. Vary the temperature $\\tau$ and find the best possible value. Conclude.\n",
        "\n",
        "*Hint:* To select actions with different probabilities, check the doc of `rng.choice()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "irl3M9qYaT8v"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class SoftmaxAgent:\n",
        "    def __init__(self, bandit, alpha, t):\n",
        "        self.bandit = bandit\n",
        "        self.alpha = alpha\n",
        "        self.Q_t = np.zeros(bandit.nb_actions)\n",
        "        self.t = t\n",
        "\n",
        "        self.optimal_action = []\n",
        "\n",
        "    def act(self):\n",
        "        action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "        return action\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        self.Q_t[action] = self.Q_t[action] + self.alpha * (reward - self.Q_t[action])\n",
        "\n",
        "    def train(self, nb_steps):\n",
        "        for t in range(nb_steps):\n",
        "          action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "\n",
        "          # softmax selection\n",
        "          prob = []\n",
        "\n",
        "          for a in range(self.bandit.nb_actions):\n",
        "            sum = 0\n",
        "            for b in range(self.bandit.nb_actions):\n",
        "                sum += math.exp(((self.Q_t[b] - self.Q_t.max())/self.t))\n",
        "            prob.append(math.exp((self.Q_t[a] - self.Q_t.max()) / self.t) / sum )\n",
        "\n",
        "          # chose reward based on probabilites\n",
        "          action = rng.choice(range(self.bandit.nb_actions), p=prob)\n",
        "\n",
        "          reward = self.bandit.step(action)\n",
        "          self.update(action, reward)\n",
        "\n",
        "\n",
        "          if a == bandit.a_star:\n",
        "            self.optimal_action.append(1)\n",
        "          else:\n",
        "            self.optimal_action.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_actions = 5\n",
        "\n",
        "rewards_epsilon_softmax = []\n",
        "optimal_epsilon_softmax = []\n",
        "\n",
        "for i in range(200):\n",
        "  bandit = Bandit(nb_actions)\n",
        "  agent = SoftmaxAgent(bandit, alpha=0.1, t=0.5)\n",
        "  agent.train(200)\n",
        "\n",
        "  rewards_epsilon_softmax.append(agent.Q_t)\n",
        "  optimal_epsilon_softmax.append(1) if agent.act() == bandit.a_star else optimal_epsilon_softmax.append(0)\n",
        "\n",
        "rewards_epsilon_softmax = np.mean(rewards_epsilon_softmax, axis=0)\n",
        "optimal_epsilon_softmax = np.mean(optimal_epsilon_softmax, axis=0)\n",
        "\n",
        "print(rewards_epsilon_softmax)\n",
        "print(optimal_epsilon_softmax)\n",
        "# ~5% besser als epsilon-Greedy"
      ],
      "metadata": {
        "id": "oyW2_HD9thfF",
        "outputId": "d08fd361-8bab-4a0a-8c1b-56930253d4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10826468 0.10526573 0.05089136 0.01661208 0.03115706]\n",
            "0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhmUKWowaT8v"
      },
      "source": [
        "## Exploration scheduling\n",
        "\n",
        "The problem with this version of softmax (with a constant temperature) is that even after it has found the optimal action, it will still explore the other ones (although more rarely than at the beginning). The solution is to **schedule** the exploration parameter so that it explores a lot at the beginning (high temperature) and gradually switches to more exploitation (low temperature).\n",
        "\n",
        "Many schemes are possible for that, the simplest one (**exponential decay**) being to multiply the value of $\\tau$ by a number very close to 1 after **each** play:\n",
        "\n",
        "$$\\tau = \\tau \\times (1 - \\tau_\\text{decay})$$\n",
        "\n",
        "**Q:** Implement in a class `SoftmaxScheduledAgent` temperature scheduling for the softmax algorithm ($\\epsilon$-greedy would be similar) with $\\tau=1$ initially and $\\tau_\\text{decay} = 0.01$ (feel free to change these values). Plot the evolution of `tau` and of the standard deviation of the choices of the optimal action. Conclude."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class SoftmaxScheduleAgent:\n",
        "    def __init__(self, bandit, alpha, t, tau_decay):\n",
        "        self.bandit = bandit\n",
        "        self.alpha = alpha\n",
        "        self.Q_t = np.zeros(bandit.nb_actions)\n",
        "        self.t = t\n",
        "        self.tau_decay = tau_decay\n",
        "\n",
        "        self.optimal_action = []\n",
        "\n",
        "    def act(self):\n",
        "        action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "        return action\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        self.Q_t[action] = self.Q_t[action] + self.alpha * (reward - self.Q_t[action])\n",
        "\n",
        "    def train(self, nb_steps):\n",
        "        for t in range(nb_steps):\n",
        "          action = rng.choice(np.where(self.Q_t == self.Q_t.max())[0])\n",
        "\n",
        "          # softmax selection\n",
        "          prob = []\n",
        "\n",
        "          for a in range(self.bandit.nb_actions):\n",
        "            sum = 0\n",
        "            for b in range(self.bandit.nb_actions):\n",
        "                sum += math.exp(((self.Q_t[b] - self.Q_t.max())/self.t))\n",
        "            prob.append(math.exp((self.Q_t[a] - self.Q_t.max()) / self.t) / sum )\n",
        "\n",
        "          # chose reward based on probabilites\n",
        "          action = rng.choice(range(self.bandit.nb_actions), p=prob)\n",
        "\n",
        "          reward = self.bandit.step(action)\n",
        "          self.update(action, reward)\n",
        "\n",
        "\n",
        "          if a == bandit.a_star:\n",
        "            self.optimal_action.append(1)\n",
        "          else:\n",
        "            self.optimal_action.append(0)\n",
        "\n",
        "          if (self.t > self.tau_decay): self.t -= self.tau_decay"
      ],
      "metadata": {
        "id": "bKr1Y9QDtsTT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bAZp57sfaT8w",
        "outputId": "0c123bd6-9b33-4219-bb03-fe44019c3b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0307278  0.04543037 0.15798793 0.06038701 0.12202396]\n",
            "0.915\n"
          ]
        }
      ],
      "source": [
        "nb_actions = 5\n",
        "\n",
        "rewards_epsilon_softmax = []\n",
        "optimal_epsilon_softmax = []\n",
        "\n",
        "for i in range(200):\n",
        "  bandit = Bandit(nb_actions)\n",
        "  agent = SoftmaxScheduleAgent(bandit, alpha=0.1, t=1, tau_decay=0.01)\n",
        "  agent.train(200)\n",
        "\n",
        "  rewards_epsilon_softmax.append(agent.Q_t)\n",
        "  optimal_epsilon_softmax.append(1) if agent.act() == bandit.a_star else optimal_epsilon_softmax.append(0)\n",
        "\n",
        "rewards_epsilon_softmax = np.mean(rewards_epsilon_softmax, axis=0)\n",
        "optimal_epsilon_softmax = np.mean(optimal_epsilon_softmax, axis=0)\n",
        "\n",
        "print(rewards_epsilon_softmax)\n",
        "print(optimal_epsilon_softmax)\n",
        "# ~1-3% besser als Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrZVSHOEaT8w"
      },
      "source": [
        "**Q:** Experiment with different schedules (initial values, decay rate) and try to find the best setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "MrBQaCNeaT8w",
        "outputId": "5ab1a405-91f0-4153-8432-d45e48bce9a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0: [-0.06162218  0.11301251  0.02364648 -0.00950577  0.0879061 ]\n",
            "2.0: 0.885\n",
            "1.0: [0.16440538 0.10114884 0.15679042 0.12806191 0.14818823]\n",
            "1.0: 0.895\n",
            "0.9: [0.06499229 0.03044532 0.10678838 0.04260966 0.1587727 ]\n",
            "0.9: 0.88\n",
            "0.8: [0.03861334 0.126923   0.15383056 0.15608334 0.11579599]\n",
            "0.8: 0.875\n",
            "0.7: [0.12127467 0.00504929 0.10854016 0.08432419 0.08849957]\n",
            "0.7: 0.845\n",
            "0.6: [0.21400385 0.1298018  0.17902756 0.19425879 0.07133216]\n",
            "0.6: 0.87\n",
            "0.5: [0.19121412 0.19401679 0.10979838 0.19974832 0.0831052 ]\n",
            "0.5: 0.785\n"
          ]
        }
      ],
      "source": [
        "nb_actions = 5\n",
        "\n",
        "\n",
        "\n",
        "tau_start_values = [2.0, 1.0, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
        "for tau in tau_start_values:\n",
        "  rewards_epsilon_softmax = []\n",
        "  optimal_epsilon_softmax = []\n",
        "\n",
        "  for i in range(200):\n",
        "    bandit = Bandit(nb_actions)\n",
        "    agent = SoftmaxScheduleAgent(bandit, alpha=0.1, t=tau, tau_decay=0.01)\n",
        "    agent.train(200)\n",
        "\n",
        "    rewards_epsilon_softmax.append(agent.Q_t)\n",
        "    optimal_epsilon_softmax.append(1) if agent.act() == bandit.a_star else optimal_epsilon_softmax.append(0)\n",
        "\n",
        "  rewards_epsilon_softmax = np.mean(rewards_epsilon_softmax, axis=0)\n",
        "  optimal_epsilon_softmax = np.mean(optimal_epsilon_softmax, axis=0)\n",
        "\n",
        "  print(f\"{tau}: {rewards_epsilon_softmax}\")\n",
        "  print(f\"{tau}: {optimal_epsilon_softmax}\")\n",
        "\n",
        "# t=1 t_d=0.01 --> 89%\n",
        "# t=1 t_d=0.05 --> 87%\n",
        "# t=0.5 t_d=0.05 --> 87.5%\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNK13HpXlRan"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3d24234067c217f49dc985cbc60012ce72928059d528f330ba9cb23ce737906d"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}